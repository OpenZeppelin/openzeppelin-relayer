events {
    worker_connections 4096;
    use epoll;
    multi_accept on;
}

http {
    # Upstream configuration - defines the relayer backend pool
    upstream relayer_backend {
        # Least connections load balancing strategy
        # Routes to the instance with fewest active connections
        least_conn;
        
        # Define backend servers
        server relayer-1:8080 max_fails=3 fail_timeout=30s;
        server relayer-2:8080 max_fails=3 fail_timeout=30s;
        server relayer-3:8080 max_fails=3 fail_timeout=30s;
        
        # Keep alive connections to backends
        keepalive 32;
    }

    # Connection and timeout settings
    keepalive_timeout 65;
    keepalive_requests 100;
    
    # Buffer settings for better performance
    client_body_buffer_size 128k;
    client_max_body_size 10m;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 8k;
    
    # Proxy buffering settings
    proxy_buffering on;
    proxy_buffer_size 4k;
    proxy_buffers 8 4k;
    proxy_busy_buffers_size 8k;

    # Logging
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log warn;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript 
               application/json application/javascript application/xml+rss 
               application/rss+xml font/truetype font/opentype 
               application/vnd.ms-fontobject image/svg+xml;

    server {
        listen 80;
        server_name _;

        # Health check endpoint
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # Main application routes
        location / {
            # Proxy to backend pool
            proxy_pass http://relayer_backend;
            
            # Proxy headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Request-ID $request_id;
            
            # Timeouts
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            # HTTP version and keep-alive
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            
            # Disable buffering for SSE/streaming if needed
            # proxy_buffering off;
            
            # Error handling - try next upstream on error
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 3;
            proxy_next_upstream_timeout 30s;
        }

        # Metrics endpoint (if exposed)
        location /metrics {
            proxy_pass http://relayer_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            access_log off;
        }

        # Swagger UI (if enabled)
        location /swagger-ui/ {
            proxy_pass http://relayer_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }

        # Status page showing load balancer stats
        location /nginx_status {
            stub_status;
            access_log off;
            # Restrict access in production
            # allow 127.0.0.1;
            # deny all;
        }
    }
}

